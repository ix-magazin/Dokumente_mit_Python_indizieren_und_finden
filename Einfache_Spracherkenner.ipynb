{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e3e58d-2376-45df-8e44-9c0958d09df9",
   "metadata": {},
   "source": [
    "# Einfacher Spracherkenner\n",
    "\n",
    "Idee: Untersuche die Verteilung von Buchstaben-Trigrammen.\n",
    "\n",
    "Für jede zu erkennende Sprache wird ein Wikipediaartikel geladen. Die Buchstabenverteilung dort dient als Bezugsgröße.\n",
    "\n",
    "Die Instanz `cv = CountVectorizer( analyzer='char', ngram_range=(3,3))` bereitet die Trigrammerstellung vor. Die Liste von Texten (Liste von Listen) in `doc` erzeugt mittels\n",
    "`cv.fit_transform(doc)` die Verteilungsmatrix. Nach einer Transposition entspicht jede Spalte einer Sprache, jede Zeile einem Trigramm.\n",
    "\n",
    "Der Test, in welcher Sprache ein Text verfasst ist, beruht auf einem Ähnlichkeitsvergleich zwischen Satz und Verteilungsmatrix. Dazu wird zunächst Text analog zur Verteilungsmatrix in einen Verteilungsvektor übeführt. Eine Normierung unterbleibt an dieser Stelle (siehe *Optimierungen*). Das Skalarprodukt aus jeweils einer Spalte der Verteilungsmatrix *dfi* und des Verteilungsvektors *q* ist ein Maß für die Übereinstimmung *cos(x)*:\n",
    "\n",
    "cos(x) * |dfi| * |q| = dfi * q  <=>\n",
    "\n",
    "cos(X) = dfi * q / (|dfi| * |q|)\n",
    "\n",
    "$$\n",
    "k(x, y) = \\frac{x y^\\top}{\\|x\\| \\|y\\|}\n",
    "$$\n",
    "\n",
    "Dafür gibt es auch eine Methode:\n",
    "\n",
    "`from sklearn.metrics.pairwise import cosine_similarity`\n",
    "`cosx = cosine_similarity([df.iloc[:, i].values], [q_vec]).item()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3f28d-2332-41ce-ad30-d0828dba8867",
   "metadata": {},
   "source": [
    "## Optimierungen\n",
    "\n",
    "Viele Optimierungsschitte fehlen:\n",
    "\n",
    "* Aufbereiten der Texte, aus der die Verteilungsstatistik abgeleitet wird.\n",
    "* Verkürzen der Verteilungsmatrix auf die Einträge, die ausreichend stark besetzt sind (7000 Trigramme sind unnötig)\n",
    "* Rolle der Leerzeichen: helfen sie bei der Unterscheidung?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c9ac4d-06c3-4d61-8286-b88335feb4cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5682fae4-65fc-472a-b7f4-4122cd11339d",
   "metadata": {
    "id": "gIS0d6YRvGA9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import re\n",
    "import string\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import wikip\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58c8365e-c5b1-4a42-b4ce-6225ab9552ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "READDATA = False # load data from wikipedia otherwise local\n",
    "fno = 'data/corpusD2s_deennlit.csv'\n",
    "fnot = 'data/corpusD2st_deennlit.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6366d0-c393-4cc3-853b-e94cb0287c4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "articles = ['https://de.wikipedia.org/wiki/Data_Science', 'https://en.wikipedia.org/wiki/Data_science', \n",
    "            'https://nl.wikipedia.org/wiki/Datawetenschap', 'https://it.wikipedia.org/wiki/Scienza_dei_dati']\n",
    "articles_cc = ['DE', 'EN', 'NL', 'IT']\n",
    "\n",
    "assert len(articles) == len(articles_cc), \"misfit articles_cc and articles\"\n",
    "\n",
    "wiki_lst=[]\n",
    "title=[]\n",
    "\n",
    "if READDATA: \n",
    "    for article in articles:\n",
    "       print(\"loading content: \",article)\n",
    "       wiki_lst.append(wikip.get_wikipedia_text(article))\n",
    "       title.append(article.split('/')[-1])\n",
    "    corpusDs = pd.DataFrame({'article': wiki_lst})\n",
    "    corpusDst = pd.DataFrame({'article': wiki_lst, 'title': title})\n",
    "    corpusDs.to_csv(fno,  index = None)\n",
    "    corpusDst.to_csv(fnot,  index = None)\n",
    "else:\n",
    "    corpusDs = pd.read_csv(fno)\n",
    "    corpusDst = pd.read_csv(fnot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f91d8e-a44e-44dd-bdb5-eee80a6ec58b",
   "metadata": {},
   "source": [
    "Vorbereiten der Daten, um die Vergleichsstatistik für die Trigramme zu erzeugen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7595fd04-6814-4c16-9900-7aa526356328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare list of lists, each list one language sample.\n",
    "\n",
    "docs = corpusDs['article'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b88722-cd2b-4cd1-9981-3255df5035d9",
   "metadata": {},
   "source": [
    "Erzeugen der normierten Verteilungsmatrix. Jede Spalte entspricht einer Sprache, jede Zeile einem Trigramm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09d83914-5e71-4ac0-b53a-1185c49d3f76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3811, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DE</th>\n",
       "      <th>EN</th>\n",
       "      <th>NL</th>\n",
       "      <th>IT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>\"a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"c</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"d</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020914</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"e</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>\"f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      DE        EN   NL        IT\n",
       " \"a  0.0  0.000000  0.0  0.004103\n",
       " \"c  0.0  0.002988  0.0  0.000000\n",
       " \"d  0.0  0.020914  0.0  0.000000\n",
       " \"e  0.0  0.002988  0.0  0.000000\n",
       " \"f  0.0  0.002988  0.0  0.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv = CountVectorizer( analyzer='char', ngram_range=(3,3))#'char_wb'\n",
    "cv = TfidfVectorizer(use_idf=False , norm='l2', analyzer='char', ngram_range=(3,3))\n",
    "X = cv.fit_transform(docs)\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(X.T.toarray(), index=cv.get_feature_names_out(), columns=articles_cc)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d80cae7-6db2-41a6-96ff-30df201c1fe5",
   "metadata": {},
   "source": [
    "Nach Anpassung des Abfragesatzes `q_vec` wird verglichen:\n",
    "\n",
    "Ähnlichkeit cos(x) =  dfi * q / (|dfi| * |q|)\n",
    "    \n",
    "`np.dot(df.iloc[:, i].values, q_vec) / np.linalg.norm(df.iloc[:, i]) * np.linalg.norm(q_vec)`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbdf2642-7226-4d0f-ba6f-bfca4dc4d31b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 524
    },
    "id": "memATAT_6CtF",
    "outputId": "bdfde847-37fa-43e7-e776-d504c18de92e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query: aber ich kaufe lieber in Geschäften\n",
      "Similarity: 0.2133 to DE\n",
      "Similarity: 0.115 to NL\n",
      "Similarity: 0.0722 to EN\n",
      "Similarity: 0.05532 to IT\n",
      "\n",
      "query: De in de index opgenomen aandelen vertegenwoordigen ongeveer\n",
      "Similarity: 0.396 to NL\n",
      "Similarity: 0.2744 to DE\n",
      "Similarity: 0.134 to EN\n",
      "Similarity: 0.1174 to IT\n",
      "\n",
      "query: Inoltre, è stata introdotta una nuova condizione rigorosa\n",
      "Similarity: 0.226 to IT\n",
      "Similarity: 0.1917 to EN\n",
      "Similarity: 0.1135 to DE\n",
      "Similarity: 0.11 to NL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_similar_articles(q, df, vec): \n",
    "    \"\"\"\n",
    "    calculate similariy between df (-Matrix) and q\n",
    "    The query q may contain \n",
    "    \n",
    "     input: query, TF-IDF-Matrix, TfidfVectorizer-instance\n",
    "        convert inquiry to TF-IDF vector\n",
    "        calculate  TF-IDF_article_i * transformed(q)\n",
    "    output: dictionary{document_index: similarity}\n",
    "    \"\"\"\n",
    "    no_articles = df.shape[1]\n",
    "    print(\"query:\", q)\n",
    "    q = [q] #not normalized (otherwise the few values may be become too small)\n",
    "    q_vec = vec.transform(q).toarray().reshape(df.shape[0],)\n",
    "    sim = {}\n",
    "    for i in range(4): #df.shape[1]):\n",
    "        #sim[i] = np.dot(df.iloc[:, i].values, q_vec) / np.linalg.norm(df.iloc[:, i]) * np.linalg.norm(q_vec)\n",
    "        sim[i] = cosine_similarity([df.iloc[:, i].values], [q_vec]).item()\n",
    "    sim_sorted = sorted(sim.items(), key=lambda x: x[1], reverse=True)\n",
    "    return(sim_sorted)\n",
    "\n",
    "def process_result(sim_sorted):\n",
    "    \"\"\"\n",
    "    nice output of results\n",
    "    input: dictionary{document_index: similarity}\n",
    "        print(index, similarity, document title)\n",
    "    \"\"\"\n",
    "    global corpusDst\n",
    "\n",
    "    for k, v in sim_sorted:\n",
    "        if v != 0.0:\n",
    "            print(f'Similarity: {v:.4g} to {df.columns[k]}')\n",
    "\n",
    "list_of_queries = ['aber ich kaufe lieber in Geschäften', \n",
    "                   'De in de index opgenomen aandelen vertegenwoordigen ongeveer',\n",
    "                   'Inoltre, è stata introdotta una nuova condizione rigorosa']\n",
    "\n",
    "for q in list_of_queries:\n",
    "    process_result(get_similar_articles(q, df, cv ))\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f5153-bbde-4f82-993c-d5a660ed8ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a55cf6ed-99e1-46cb-bf55-88974680c4c9",
   "metadata": {},
   "source": [
    "## Vergleich der häufigsten Trigramme"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9f42824-0a80-41b9-89c1-414644cbd69a",
   "metadata": {},
   "source": [
    "# Have a look on trigram distribution of languages\n",
    "\n",
    "# DE, EN, NL, IT\n",
    "\n",
    "print(corpusDs.shape)\n",
    "s1 = corpusDs.iloc[3,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83738203-3aa2-4fda-a437-3db55fd8d016",
   "metadata": {},
   "source": [
    "cv = CountVectorizer( analyzer='char', ngram_range=(3,3) )#'char_wb'\n",
    "X = cv.fit_transform([s1])\n",
    "X\n",
    "df = pd.DataFrame(X.todense(), columns=cv.get_feature_names()).T.sort_values(by=0, ascending=False)\n",
    "df = df.iloc[:,0]/df.iloc[:,0].sum(axis=0)\n",
    "#df = df[df>0.005]\n",
    "print(X.shape)\n",
    "len(cv.vocabulary_)\n",
    "X.todense()\n",
    "#cv.get_feature_names_out()\n",
    "len(cv.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f98b323a-fd88-45b3-ac16-586a88ad6019",
   "metadata": {},
   "source": [
    "The main trigrammes in DE, EN, NL, IT\n",
    "\n",
    "de\n",
    "en     0.014790\n",
    "er     0.009636\n",
    " da    0.008964\n",
    " de    0.008590\n",
    "dat    0.008217\n",
    "die    0.008142\n",
    "ien    0.008068\n",
    "sch    0.007843\n",
    "ten    0.007246\n",
    " an    0.006125\n",
    " un    0.006051\n",
    "der    0.005752\n",
    "ter    0.005677\n",
    " di    0.005677\n",
    "ers    0.005602\n",
    " sc    0.005378\n",
    "ie     0.005378\n",
    "nd     0.005229\n",
    "ta     0.005005\n",
    "\n",
    "en\n",
    "dat    0.010103\n",
    "ata    0.009952\n",
    " th    0.009952\n",
    "ati    0.009801\n",
    " an    0.009650\n",
    " da    0.009047\n",
    "sci    0.008444\n",
    " in    0.008293\n",
    "the    0.008142\n",
    "ta     0.007992\n",
    "nce    0.007690\n",
    "cie    0.007690\n",
    "ien    0.007539\n",
    "and    0.007539\n",
    " sc    0.007388\n",
    "nd     0.007388\n",
    "enc    0.007238\n",
    "ion    0.007238\n",
    "he     0.006785\n",
    "ing    0.006634\n",
    "ed     0.006634\n",
    "tio    0.006333\n",
    "a s    0.005277\n",
    "ng     0.005127\n",
    "\n",
    "nl\n",
    "en     0.024108\n",
    "an     0.008809\n",
    " va    0.008345\n",
    "ens    0.008345\n",
    "dat    0.008345\n",
    " en    0.008345\n",
    "ati    0.008345\n",
    " in    0.007881\n",
    "de     0.007881\n",
    " da    0.007881\n",
    "ata    0.007418\n",
    "van    0.006954\n",
    "tie    0.006954\n",
    "et     0.006954\n",
    "ten    0.006490\n",
    " he    0.006490\n",
    "sch    0.006490\n",
    "het    0.006490\n",
    "ete    0.006027\n",
    "nsc    0.005563\n",
    "hap    0.005563\n",
    "cha    0.005563\n",
    " ge    0.005563\n",
    "wet    0.005100\n",
    "\n",
    "it\n",
    "ati    0.013963\n",
    " de    0.013520\n",
    " da    0.012855\n",
    "i d    0.010860\n",
    "dat    0.009752\n",
    " di    0.009087\n",
    "la     0.008200\n",
    "e d    0.007979\n",
    "a d    0.007979\n",
    "di     0.007314\n",
    "sci    0.007314\n",
    "ti     0.007092\n",
    "ien    0.006871\n",
    " co    0.006649\n",
    "ei     0.006649\n",
    "enz    0.006427\n",
    "dei    0.006206\n",
    " sc    0.005984\n",
    "ell    0.005984\n",
    "del    0.005984\n",
    "to     0.005762\n",
    "tic    0.005762\n",
    "cie    0.005762\n",
    "za     0.005319\n",
    "a s    0.005319\n",
    " in    0.005098\n",
    "nza    0.005098"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
